{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708d488a-8455-4f9f-ab9e-3be8b189c184",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Initial Summarization Using Ollama\n",
    " \n",
    "The journey began with a foundational step: analyzing the content of Kamatech Solutions' website.\n",
    "Leveraging [Ollama](https://ollama.com/) a free and no paid API that runs locally on your computer, two language models were employed to extract concise and informative summaries of the website's content.\n",
    "The focus was on capturing the essence of Kamatech solutions' products or services, their value proposition, their target and industry focus, as well as any notable aspects or their approach and methodology.\n",
    "        \n",
    "#### Stepping Into LLM Engineering\n",
    "\n",
    "This initial analysis served as a critical starting point for a broader LLM Engineering journey.\n",
    "Future steps will include building advanced models, customizing them to solve domain-specific problems, refining natural language understanding capabilities, and expanding multilingual features even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3de2646-65cd-49c9-bf4c-b00a2a705641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import requests\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6935e6ba-9c3a-458a-a047-7ebfe9407aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website Summary:\n",
      " The provided HTML code appears to be a webpage that displays a blog post list with an option to load more posts when the user clicks a \"Load More\" button. The JavaScript code handles the AJAX request for loading more posts and adjusts the UI accordingly. There's also some CSS to style the page, such as adding a loading state when new content is being fetched. Overall, it looks like an optimized blog layout using AJAX to improve user experience by only loading the initial set of posts and allowing users to fetch more as needed.\n"
     ]
    }
   ],
   "source": [
    "# Fetch the website content\n",
    "response = requests.get('https://www.kamatechsolutions.com')\n",
    "website_content = response.text\n",
    "\n",
    "# Create a JSON payload for Ollama API\n",
    "payload = {\n",
    "    \"model\": \"mistral\",\n",
    "    \"prompt\": f\"Summarize the following website content in 3-8 sentences: {website_content}\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Call Ollama API (assuming it's running locally on default port)\n",
    "    ollama_response = requests.post('http://localhost:11434/api/generate', json=payload)\n",
    "    \n",
    "    # Check if response is valid\n",
    "    if ollama_response.status_code == 200:\n",
    "        # Parse the streaming response\n",
    "        response_text = \"\"\n",
    "        for line in ollama_response.text.strip().split('\\n'):\n",
    "            if line:\n",
    "                try:\n",
    "                    response_json = json.loads(line)\n",
    "                    if 'response' in response_json:\n",
    "                        response_text += response_json['response']\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        summary = response_text if response_text else \"No summary generated\"\n",
    "    else:\n",
    "        summary = f\"Error: Received status code {ollama_response.status_code}\"\n",
    "except Exception as e:\n",
    "    summary = f\"Error: {str(e)}\"\n",
    "\n",
    "print(\"Website Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf1f12-8ade-4468-b96e-49d34c68a746",
   "metadata": {},
   "source": [
    "### Interpretation: \n",
    "\n",
    "The above summary we received is focused on the website's technical implementation rather than its actual content. This often happens when the the model analyzes the raw HTML, CSS or JavaScript codes instead of the website text content that human visitors would see.\n",
    "\n",
    "**Here is the approch to improve the summary quality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79fd0dd1-4aed-40c9-892e-bb22b9fc4010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Summary: 1. Company Name and Business Type:\n",
      "     - Name: KamaTech Solutions\n",
      "     - Business Type: IT Consulting Firm\n",
      "\n",
      "  2. Main Products / Services:\n",
      "     - Custom Software Development\n",
      "     - Mobile Application Development\n",
      "     - Web Application Development\n",
      "     - DevOps Services\n",
      "     - Quality Assurance and Testing\n",
      "     - UI/UX Design\n",
      "\n",
      "  3. Value Proposition and USP:\n",
      "     - Delivering high-quality IT solutions that meet client needs and expectations.\n",
      "     - Combining deep technical expertise with strong business acumen to provide tailored solutions.\n",
      "     - A commitment to innovation, quality, and customer satisfaction.\n",
      "\n",
      "  4. Target Audience / Industry:\n",
      "     - Businesses across various industries in need of custom IT solutions.\n",
      "     - Specific industries mentioned: Healthcare, Finance, Retail, Education, and Real Estate.\n",
      "\n",
      "  5. Notable Methodologies/Approaches:\n",
      "     - Agile Development Methodology\n",
      "     - DevOps Practices\n",
      "     - Lean UX Design Principles\n",
      "     - Scrum Framework\n",
      "     - Continuous Integration and Delivery (CI/CD)\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import requests\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "OLLAMA_API_URL = 'http://localhost:11434/api/generate'  # Default Ollama API endpoint\n",
    "DEFAULT_MODEL = 'mistral'  # Use mistral as the default model\n",
    "DEFAULT_MAX_TOKENS = 200  # Adjust as needed\n",
    "DEFAULT_TEMPERATURE = 0.5  # Adjust as needed\n",
    "REQUEST_TIMEOUT = 200  # seconds (Ollama can take longer to respond)\n",
    "\n",
    "def call_ollama_api(prompt: str, model: str = DEFAULT_MODEL, max_tokens: int = DEFAULT_MAX_TOKENS, temperature: float = DEFAULT_TEMPERATURE) -> Optional[str]:\n",
    "    try:\n",
    "        data = {\n",
    "            'model': model,\n",
    "            'prompt': prompt,\n",
    "            'max_tokens': max_tokens,\n",
    "            'temperature': temperature,\n",
    "            'stream': False  # Set to False to get a single response\n",
    "        }\n",
    "\n",
    "        # Send the request to the Ollama API\n",
    "        response = requests.post(OLLAMA_API_URL, json=data, timeout=REQUEST_TIMEOUT)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Extract the response content\n",
    "        result = response.json()\n",
    "        return result.get('response', '').strip()\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Request error calling Ollama API: {e}\")\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Key error in parsing Ollama API response: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error calling Ollama API: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    prompt =  f\"\"\"Extract the following information from https://kamatechsolutions.com:\n",
    "        1. Company name and business type\n",
    "        2. Main products / services\n",
    "        3. Value proposition and USP\n",
    "        4. Target audience / industry\n",
    "        5. Notable methodologies/approaches\n",
    "\n",
    "        Present as concise bullet points. Only include explicitly stated facts.\n",
    "        \"\"\"\n",
    "    summary = call_ollama_api(prompt)\n",
    "    if summary:\n",
    "        logger.info(f\"Summary: {summary}\")\n",
    "    else:\n",
    "        logger.error(\"Failed to generate summary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa64186-3f24-4e31-a1f3-7ffb7c937696",
   "metadata": {},
   "source": [
    "#### Leveraging BeautiulSoup for webscraping:\n",
    "- Use beautifulSoup to properly extract content from the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9a4188-08cc-420c-ac0b-26cf9e2a0392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing https://www.kamatechsolutions.com...\n",
      "- Content extracted (8003 chars) in 1.41s\n",
      "- Summary generated in 263.04s\n",
      "\n",
      "Total time: 264.45s\n",
      "\n",
      "SUMMARY:\n",
      "1. Company name: Kamatech Solutions\n",
      "    2. Main products or services offered: Advanced Analytics consulting services, including Data Science, Machine Learning, and Artificial Intelligence.\n",
      "    3. Value proposition: Unload your analytics burden to KAMA-TECH SOLUTIONS, where the project is their priority. They provide workable data-driven IT business solutions, using the latest technology equipment and offering big data analytics, business intelligence (BI), data analytics, I business analytics, database and system design, etc.\n",
      "    4. Service regions: Worldwide (as specified in the country list provided)\n",
      "    5. Contact details: Email: info@kamatechsolutions.com; Phone: (281) 676-3571\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "\n",
    "def summarize_website(url, model=\"mistral\"):\n",
    "    \"\"\"Fetch website content and generate a summary using Ollama API\"\"\"\n",
    "    print(f\"Processing {url}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fetch and parse website content\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Remove non-content elements\n",
    "        for element in soup(['script', 'style', 'meta', 'link', 'noscript', 'iframe']):\n",
    "            element.decompose()\n",
    "        \n",
    "        # Extract visible text (limit to 8000 chars if needed)\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "        text = text[:8000] + \"...\" if len(text) > 8000 else text\n",
    "        \n",
    "        print(f\"- Content extracted ({len(text)} chars) in {time.time() - start_time:.2f}s\")\n",
    "        \n",
    "        # Generate summary using Ollama\n",
    "        prompt = f\"\"\"\n",
    "        Based on this website content, summarize:\n",
    "        1. Company name and business type\n",
    "        2. Main products or services offered\n",
    "        3. Value proposition\n",
    "        4. Target audience\n",
    "        5. Notable methodologies\n",
    "\n",
    "        Present as concise bullet points. Only include explicitly stated facts.\n",
    "        \n",
    "        Website content: {text}\n",
    "        \"\"\"\n",
    "        \n",
    "        ollama_start = time.time()\n",
    "        \n",
    "        # Use stream=True to handle streaming response properly\n",
    "        response = requests.post(\n",
    "            'http://localhost:11434/api/generate', \n",
    "            json={\"model\": model, \"prompt\": prompt},\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Extract the summary from streaming response\n",
    "        summary = \"\"\n",
    "        if response.status_code == 200:\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    try:\n",
    "                        data = json.loads(line)\n",
    "                        if 'response' in data:\n",
    "                            summary += data['response']\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "        else:\n",
    "            summary = f\"Error: API returned status code {response.status_code}\"\n",
    "        \n",
    "        print(f\"- Summary generated in {time.time() - ollama_start:.2f}s\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total_start = time.time()\n",
    "    summary = summarize_website('https://www.kamatechsolutions.com')\n",
    "    print(f\"\\nTotal time: {time.time() - total_start:.2f}s\")\n",
    "    print(\"\\nSUMMARY:\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541f82e-7bdc-4652-a23e-59c6cd1990fc",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f87fba2-cb67-472a-b91c-b55a9095671c",
   "metadata": {},
   "source": [
    "### Key takeaways :\n",
    "- The model uses **[mistral](https://ollama.com/search)** which is a smaller,faster model and the one of the most popular open-source models available in **Ollama**.\n",
    "- No API Key is needed: **Ollama** runs locally, so no API Key is required.\n",
    "- Customization: You can adjust the max_tokens and temperature parameters to control the response lengh and creativity.\n",
    "\n",
    "### Alternative model in Ollama :\n",
    "If you want to experiment with other models, you can replace **mistral** with one of the following:\n",
    "- gemma3 : the current, most capable model that runs on a single GPU\n",
    "- vicuna : a fine-tuned version of llama for conversational tasks\n",
    "- llama3 : The most capable openly available LLM to date\n",
    "\n",
    "To use a different model, make sure the model is isntalled loccally using Ollama. Simply pull it using ollama pull **model name** (e.g **ollama pull llama3**) and update the **model** constant in the code.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
